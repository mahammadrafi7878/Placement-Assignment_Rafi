{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlfQfX5aBGPe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "e8C6GUYEBlPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaTvfIR5CBpL",
        "outputId": "57c1adc4-36c0-4d14-bcb8-ef2b3a0d7bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images=np.expand_dims(test_images,axis=-1)"
      ],
      "metadata": {
        "id": "9fits8PNCK_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nae3IDRvCXbg",
        "outputId": "3a4af99c-a89c-4b6f-8436-d95b391ea9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbcd34KOCimF",
        "outputId": "fbf345a0-630c-498b-b2d4-f395a393c508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = tf.image.resize(train_images, [24,24])\n",
        "test_images=tf.image.resize(test_images, [24,24])"
      ],
      "metadata": {
        "id": "lkHkLvI5Cxcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQaDruMDJhTX",
        "outputId": "92a8246c-0c0f-45d5-8e9d-e9a77d093ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 24, 24, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(24, (3, 3), activation='relu', input_shape=(24, 24, 1)))\n",
        "model.add(layers.Conv2D(24, (3, 3), activation='relu',strides=(2, 2)))\n",
        "model.add(layers.Conv2D(48, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(48, (3, 3), activation='relu',strides=(2, 2)))\n",
        "model.add(layers.Conv2D(96, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(96, (1, 1), activation='relu'))\n",
        "model.add(layers.Conv2D(81, (1, 1), activation='relu'))\n",
        "model.add(layers.GlobalAveragePooling2D())\n"
      ],
      "metadata": {
        "id": "fUKYnU0LC2V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s23G3-NSIWxL",
        "outputId": "95e9e0fa-d088-48b8-dfb9-ec9d51de699b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          (None, 22, 22, 24)        240       \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 10, 10, 24)        5208      \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 8, 8, 48)          10416     \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 3, 3, 48)          20784     \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 1, 1, 96)          41568     \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 1, 1, 96)          9312      \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 1, 1, 81)          7857      \n",
            "                                                                 \n",
            " global_average_pooling2d_8   (None, 81)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 95,385\n",
            "Trainable params: 95,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OuufaNsAI01U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, epochs=75, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d43-DWMHJDNj",
        "outputId": "52f41fac-5e56-49a2-f67a-eb9256051d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0949 - val_accuracy: 0.9897\n",
            "Epoch 2/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0736 - val_accuracy: 0.9908\n",
            "Epoch 3/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0867 - val_accuracy: 0.9914\n",
            "Epoch 4/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.0968 - val_accuracy: 0.9892\n",
            "Epoch 5/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0967 - val_accuracy: 0.9899\n",
            "Epoch 6/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1048 - val_accuracy: 0.9895\n",
            "Epoch 7/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1016 - val_accuracy: 0.9892\n",
            "Epoch 8/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.1074 - val_accuracy: 0.9909\n",
            "Epoch 9/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1136 - val_accuracy: 0.9875\n",
            "Epoch 10/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.1211 - val_accuracy: 0.9892\n",
            "Epoch 11/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.1389 - val_accuracy: 0.9879\n",
            "Epoch 12/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0970 - val_accuracy: 0.9905\n",
            "Epoch 13/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0993 - val_accuracy: 0.9901\n",
            "Epoch 14/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1435 - val_accuracy: 0.9892\n",
            "Epoch 15/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.1160 - val_accuracy: 0.9881\n",
            "Epoch 16/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0913 - val_accuracy: 0.9906\n",
            "Epoch 17/75\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.1515 - val_accuracy: 0.9884\n",
            "Epoch 18/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.1159 - val_accuracy: 0.9907\n",
            "Epoch 19/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.1469 - val_accuracy: 0.9899\n",
            "Epoch 20/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0999 - val_accuracy: 0.9905\n",
            "Epoch 21/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0884 - val_accuracy: 0.9911\n",
            "Epoch 22/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.1149 - val_accuracy: 0.9894\n",
            "Epoch 23/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.1064 - val_accuracy: 0.9907\n",
            "Epoch 24/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0927 - val_accuracy: 0.9909\n",
            "Epoch 25/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0980 - val_accuracy: 0.9905\n",
            "Epoch 26/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.1285 - val_accuracy: 0.9894\n",
            "Epoch 27/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1110 - val_accuracy: 0.9910\n",
            "Epoch 28/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0886 - val_accuracy: 0.9918\n",
            "Epoch 29/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.1244 - val_accuracy: 0.9894\n",
            "Epoch 30/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 0.0844 - val_accuracy: 0.9919\n",
            "Epoch 31/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0896 - val_accuracy: 0.9912\n",
            "Epoch 32/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1036 - val_accuracy: 0.9906\n",
            "Epoch 33/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.1168 - val_accuracy: 0.9919\n",
            "Epoch 34/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1306 - val_accuracy: 0.9895\n",
            "Epoch 35/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1254 - val_accuracy: 0.9902\n",
            "Epoch 36/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1216 - val_accuracy: 0.9903\n",
            "Epoch 37/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.1359 - val_accuracy: 0.9899\n",
            "Epoch 38/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.1246 - val_accuracy: 0.9902\n",
            "Epoch 39/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1140 - val_accuracy: 0.9905\n",
            "Epoch 40/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.1536 - val_accuracy: 0.9896\n",
            "Epoch 41/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.1142 - val_accuracy: 0.9907\n",
            "Epoch 42/75\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0943 - val_accuracy: 0.9898\n",
            "Epoch 43/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1331 - val_accuracy: 0.9902\n",
            "Epoch 44/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.1844 - val_accuracy: 0.9863\n",
            "Epoch 45/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1565 - val_accuracy: 0.9893\n",
            "Epoch 46/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1613 - val_accuracy: 0.9893\n",
            "Epoch 47/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.2147 - val_accuracy: 0.9889\n",
            "Epoch 48/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.1546 - val_accuracy: 0.9894\n",
            "Epoch 49/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.1369 - val_accuracy: 0.9900\n",
            "Epoch 50/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.1655 - val_accuracy: 0.9900\n",
            "Epoch 51/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.1279 - val_accuracy: 0.9896\n",
            "Epoch 52/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.1232 - val_accuracy: 0.9905\n",
            "Epoch 53/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.1418 - val_accuracy: 0.9902\n",
            "Epoch 54/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.1508 - val_accuracy: 0.9898\n",
            "Epoch 55/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.1356 - val_accuracy: 0.9913\n",
            "Epoch 56/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1895 - val_accuracy: 0.9903\n",
            "Epoch 57/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.2138 - val_accuracy: 0.9877\n",
            "Epoch 58/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.1724 - val_accuracy: 0.9902\n",
            "Epoch 59/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 0.1781 - val_accuracy: 0.9884\n",
            "Epoch 60/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.1611 - val_accuracy: 0.9895\n",
            "Epoch 61/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.1663 - val_accuracy: 0.9897\n",
            "Epoch 62/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.2428 - val_accuracy: 0.9895\n",
            "Epoch 63/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 0.1621 - val_accuracy: 0.9914\n",
            "Epoch 64/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.1602 - val_accuracy: 0.9903\n",
            "Epoch 65/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.2831 - val_accuracy: 0.9872\n",
            "Epoch 66/75\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.1792 - val_accuracy: 0.9912\n",
            "Epoch 67/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.1388 - val_accuracy: 0.9912\n",
            "Epoch 68/75\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.1599 - val_accuracy: 0.9905\n",
            "Epoch 69/75\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.1505 - val_accuracy: 0.9907\n",
            "Epoch 70/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1580 - val_accuracy: 0.9904\n",
            "Epoch 71/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.1391 - val_accuracy: 0.9906\n",
            "Epoch 72/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.1658 - val_accuracy: 0.9907\n",
            "Epoch 73/75\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.1795 - val_accuracy: 0.9892\n",
            "Epoch 74/75\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.1735 - val_accuracy: 0.9898\n",
            "Epoch 75/75\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1549 - val_accuracy: 0.9896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "azgPDvjcJILn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modules=[]\n",
        "modules.append(nn.Conv2d(24, 24, (3,3)))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "modules.append(nn.Conv2d(24, 48, (3,3),stride=2))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "modules.append(nn.Conv2d(48, 48, (3,3)))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "modules.append(nn.Conv2d(48, 96, (3,3),stride=2))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "\n",
        "modules.append(nn.Conv2d(96, 96, (3,3)))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "modules.append(nn.Conv2d(96, 81, (1,1)))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "modules.append(nn.Conv2d(81, 81, (1,1)))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "modules.append(nn.AvgPool2d(kernel_size = 100))\n",
        "modules.append(nn.Softmax(dim=1))"
      ],
      "metadata": {
        "id": "jPoE7xKrPk0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = nn.Sequential(*modules)"
      ],
      "metadata": {
        "id": "JbAuBiNYRt96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_set=datasets.MNIST(root='./data',train=True,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiO-dfuAWnpR",
        "outputId": "17137387-bb65-4bcf-e6f4-86cadb5399e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 446637638.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 117721762.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 126671637.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 19823651.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_test_set=datasets.CIFAR10(root='./data',train=False,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmOVCQ2kXS_k",
        "outputId": "a91bb20c-f1a8-4ea6-f7a8-43843e3906d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13165839.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "xdMYBoy8XdP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train_set, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "6ispMPtDXut2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VibjB887ac5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = torch.nn.DataParallel(model1)"
      ],
      "metadata": {
        "id": "c86slCb1XyrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "RShcf_kuX7KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = model1.to(device)"
      ],
      "metadata": {
        "id": "P9wavxhiX-yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "gG-cjoQHYBcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for inputs,labels in train_loader:\n",
        "    inputs=inputs.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model1(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(f'Finished Training, Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "e5CJDRRaYE7I",
        "outputId": "98ca795f-626f-4ce0-89a1-a3e6388c35c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-ec68d6fdaec3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [24, 24, 3, 3], expected input[64, 1, 28, 28] to have 24 channels, but got 1 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u-GzPuyEYHcZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}